# 14102307

<h1> Urbinn </h1>

<h2> Opdrachten 1.0 </h2>
<h3> Scrum 1.1 </h3>
“How does SCRUM try to comply to the values of the agile manifesto”
Dit past bij Scrum omdat bij “Individuals and interactions over processes and tools” scrum gaat voor grooten deels over mensen di appart werken aan onderdelen maar toch samen komen om mogelijke problemen enzo te bespreken.
“Working software over comprehensive documentation” Scrum focused op deliverables stukken werkend software bijvoorbeeld over dosumenten (dit betekent niet date r geen documenten zijn)
“Customer collaboration over contract negotiation” aan het einde van elke sprint probeer je met de opdrachtgever te evalueren of het product nog op het goeie weg zit.
“Responding to change over following a plan” Scrum is hierbij heel  passend omdat je na elke sprint kan kijken of het og goed gaat of als de planning aangepast moet worden.

<h3>1.2 Presentaties</h3>
In [week 3](https://github.com/Eyegi/14102307/blob/master/Presentation/Week%203%20-%20Presentatie.pdf) heb ik mijn erste presenatie gehouden deze was op 15 september.
Ook was Kevin en ik verantwwordelijk voor het updaten van de blog in week 3 en 4. Dit is het gedeelte “Milestone 2” die te zien is op https://kb74.github.io/urbinn/
Mijn Tweede presentatie was in [week 7](/)

<h2>Online Cursussen 2.0</h2>

<h3>2.1 DataCamp</h3>
VoorData camp heb ik alle opdrachten af tot en met Week 6 afgemaakt. De Screenshots hiervan zijn te vinden in het mapje [DataCamp](https://github.com/Eyegi/14102307/tree/master/DataCamp).

<h3>2.2Coursera</h3>
Voor Coursera heb ik tot nu toe alle Quizzes tot en met week 3 van coursera gehaald. 
Echter moet i nog de programeer opdrachten nog afmaken en submitten. 
De resultaten van [Week1](https://github.com/Eyegi/14102307/blob/master/Coursera/CourseraWeek1.PNG).
De resultaten van week 2 zijn te zien in dit [screenshot](/https://github.com/Eyegi/14102307/blob/master/Coursera/Coursera%20Week%202.PNG), en week 3 kan [hier](https://github.com/Eyegi/14102307/blob/master/Coursera/CourseraWeek3.PNG) gevonden worden


<h2>4.0 Issues</h2>

<h3> [Issue 52](https://github.com/urbinn/urbinn/issues/52) Kijken hoe evaluatie TUM is gedaan:</h3>
Hierbij moest ik Onderzoek doen Samen met Bob om te kijken howe de evaluatie van de TUM database gedaan was en hierbij een document van maken. 
Dit was nodig omdat wij opzoek waren naar mogelijke evaluatie mogelijkheden voor onze eigen dataset, hieruit is een samenvatting gekomen als [resultaat](/). 


<h3>[Issue 55](https://github.com/urbinn/urbinn/issues/55) Object detection papers lezen</h3>
Hierbij moesten wij de papers van [YOLO](/) en [Mustafa](/) lezen om te kijken of het toepasbaar zou zijn voor ons project. 
En later werd deze ook de papers die wij moesten lezen voor het tweede sessie van close reading.

<h3>[Issue 57](https://github.com/urbinn/urbinn/issues/57) Beschrijven data structuur KeyFrame in ORB:</h3>
Deze ticket heeft wat tijd gekost. 
De bedoeling was om in het code vann ORB SLAM2 Comentaar te schrijven met doxygen die de uitlegd wat elke gedeelte van de code deed. 
Dit heeft tijd genomen omdat je eerst tijd in moet stoppen om de code te begrijpen en uitesten voordat je kanzeggen wat er gebeurt. 
Deze issue heb ik samen met Kevin gedaan. Resultaat is te vinden in [KeyFrame.cc](https://github.com/Eyegi/14102307/blob/master/Code/KeyFrame.cc).

<h3>[Issue 70](https://github.com/urbinn/urbinn/issues/70) KITTI point cloud resultaten:</h3>
Bij Deze issue moest de kitty data set door orb slam 2 gehaald worden om csv bestand te krijgen met alle punten voor de point cloud. Orb slam moest op de server van datasience gedraait worden maa er waren isnatlatie problemen in het begin die later zijn opgelost waardoor de KITTI dataset door orb gehaald on worden en de csv bestand te krijgen was. 
Dit is gelukt en hebben we de [csv](https://github.com/Eyegi/14102307/blob/master/Code/map.csv) bestand uitgekregen.

<h3>[Issue 30](https://github.com/urbinn/urbinn/issues/30) SVO uitproberen op test case:</h3> 
Hierbij moest ik SVO instaleren en uitproberen op mijn pc het is gelukt om het te installeren en runnen maar halverwegen de images crashed het soms omdat mijn pc niet genoeg rekenkracht voor had. Er is Besloten om verder te gaan met ORB 2 omdat beter leek te passen bij ons en is csv dus ook niet meer uitgebprobeert of gebruikt.
 

<h3>[Issue 37](https://github.com/urbinn/urbinn/issues/37) REMODE onderzoek:</h3>
Voor deze issue moest ik onderzoeken of [REMODE-methode](https://github.com/Eyegi/14102307/blob/master/Documents/ICRA14_Pizzoli.pdf) goed was om te gebruiken om afstand te meten uit beelden.
Dit bleek niet bij ons te passen omdat het voor MONO-camera’s waren en wij willen gebruik maken van stereo.

<h3>[Issue 21](https://github.com/urbinn/urbinn/issues/21) Zoeken naar tutorial/video’s voor LSD SLAM:</h3>
In het begin van het project moest ik Video’s en of tutorial zoeken die LSD SLAM kon uitleggen zodat het beter te begrijpen werd door de rest van het groepje. Er waren geen duidelijke videos die de werking LSD slam uitlegde.
Meeste videos waren voorbeelden waar met lsd slam gewerkt was.
```jjhkjhkj```

<h3>*[Issue 46](https://github.com/urbinn/urbinn/issues/46) Visualisatie point/frame:</h3>
Voor deze issue heb ik samen met Daniello gekeken hoe wij de orbs van elke afbeelding kon tonen op de afbeelding.
Dit zodat wij een idee konden krijgen waar hij orbs zette en ook ter evaluatie van onze eigen dataset voor de toekomst. 
Het is ons gelukt om de//////////////////////////////////////////////////// [X en Y-coördinatenNOTDONE](/) aan te tonen op de afbeelding maar de berekening van de diepte hebben wij nog niet goedkunnen doen.

<h3>*csv link[Issue 91](/https://github.com/urbinn/urbinn/issues/91) ORB2 pointcloud maken slinger:</h3>
Voor deze issue moest er een pointcloud gemaakt worden van de slinger om dit te doen moest er eerst een [calibratie bestand](https://github.com/Eyegi/14102307/blob/master/Code/slinger.txt) van de ZED camera geschreven worden met de correcte waardes die orb kan geruiken.
Daara moest de KITTI.cc bestand aangepast worden zodat het gebruikt kon worden voor onze bestanden deze is [slinger.cc](https://github.com/Eyegi/14102307/blob/master/Code/slinger.cc) gewroden. Hierbij moest /////////////////// aangepast worden in de kitti.cc.  Als laatste moest er ook een [timestamp](https://github.com/Eyegi/14102307/blob/master/Code/timestamps.txt) bestand gemaakt worden 
Bij eerste run hebben wij een coredumb gekregen. wij hebben hierdoor besloten om de code die wij hebben gemaakt om XML bestand te maken even weg te laten en opniew runnen toen ging het goed en hebben wij de [csv](/) bestand gekregen.

<h3> [Issue 87](https://github.com/urbinn/urbinn/issues/91) Paper zoeken voor close reading sessie</h3>
Hierbij moest ik papers zoeken voor de derde sessie van close reading sessie. De eerste was [Interactive Semantic Mapping: Experimental Evaluation](/) en de tweede was [A Proposal for Semantic Map Representation and Evaluation](/).

<h3>[Issue 81](https://github.com/urbinn/urbinn/issues/81) Literatuur scan: filteren slam met object detectie </h3>
De bedoeling hierbij was om te kijken of er eerder werk is gedaan om objecten die gedetecteerd zjn met bijvoorbeeld YOLO uit slam te filteren zodat je een symantic map kan maken zonder bv autos er in te hebben. Hierbij is er geen eerderwerk gevonden het dichts bijzijnde was objecten duidelijker maken met object detection.

<h3> [Issue 64](https://github.com/urbinn/urbinn/issues/64) Evaluatie implementatie: pointcloud vs pointcloud</h3>
Hierij moest er een manier gevonden worden om de pointcloud te evalueren. Hierbij hebben wij eerst gekeken of het op basis van LiDAR kan gebeuren maar dit was niet mogelijk. Daarna hebben wij gekeken of het kon met de mesh 
die door de ZED camera gemaakt werd maar dit was niet mogelijk omdat de mesh geen loop closure had. Er is ook geprobeert met diepte beelden maar de diepte is relatief en niet "fixed".

<h3>[Issue 79](https://github.com/urbinn/urbinn/issues/79) ORB coordinaten converteren </h3>
Bij deze issue was het de bedoeling om de coordinaten die door orb gegeven waren te vertalen naar meters.
<h3>[Issue 80](https://github.com/urbinn/urbinn/issues/80)ORB output uitbreiden met keyframe coordinaten</h3>

<h3>[Issue 126](https://github.com/urbinn/urbinn/issues/126)ORB Local Bundle Adjustment</h3>
Bij deze punt ben ik overgestapt van ORB naar URB ik moest de [Local Bundle Adjustment](/) code maken. En later kwam daniello mij hierbij helpen. 
<h3>[Issue 113](https://github.com/urbinn/urbinn/issues/113)ORB ORB2: Camera poses uit frames exporteren </h3>

<h3>[Issue 107](https://github.com/urbinn/urbinn/issues/107)ORB Orb2 stability fix </h3>
Bij het maken van grotere pointclouds en incrementeel leren zijn wij er achter gekomen dat de memory leaks te groot werden en dat het programma dan crashed. Dus moesten wij de memory leaks proberen te fixen dit heeft heel veel tijd genomen.

<h3>[Issue 137](https://github.com/urbinn/urbinn/issues/137)ORB Handmatig bepalen welke frame overlappen op Sequence 07 KITTI </h3>
*Deze isuues is nog iet af maar de bedoeling is om handmatig de de punten aar loopclosure gedecteerd moet worden te zoeken.

<h3>[Issue 136](https://github.com/urbinn/urbinn/issues/136)ORB Full BA code schrijven </h3>
Voor deze issue moest de code voor [full Bundle adjustment](/) gemaakt worden en getest hiervoor is issue 137 nodig.

<h3>[Issue 132](https://github.com/urbinn/urbinn/issues/132)ORB Efficient depth estimation </h3>
De bedoeling van deze issue was om te kijken of depth estimation sneller gemaakt kon worden maar dit was even op hold gezet om Full bundle adjustment te maken.





