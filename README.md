# 14102307

# Urbinn 

## Opdrachten 1.0 


###  Scrum 1.1 
“How does SCRUM try to comply to the values of the agile manifesto”
Dit past bij Scrum omdat bij “Individuals and interactions over processes and tools” scrum gaat voor grooten deels over mensen di appart werken aan onderdelen maar toch samen komen om mogelijke problemen enzo te bespreken.
“Working software over comprehensive documentation” Scrum focused op deliverables stukken werkend software bijvoorbeeld over dosumenten (dit betekent niet date r geen documenten zijn)
“Customer collaboration over contract negotiation” aan het einde van elke sprint probeer je met de opdrachtgever te evalueren of het product nog op het goeie weg zit.
“Responding to change over following a plan” Scrum is hierbij heel  passend omdat je na elke sprint kan kijken of het og goed gaat of als de planning aangepast moet worden.

### 1.2 Presentaties
In [week 3](https://github.com/Eyegi/14102307/blob/master/Presentation/Week%203%20-%20Presentatie.pdf) heb ik mijn erste presenatie gehouden deze was op 15 september.
Ook was Kevin en ik verantwwordelijk voor het updaten van de blog in week 3 en 4. Dit is het gedeelte “Milestone 2” die te zien is op https://kb74.github.io/urbinn/
Mijn Tweede presentatie was in [week 7](https://github.com/Eyegi/14102307/blob/master/Presentation/Week%207%20-%20Presentatie.pdf). De rest van mijn presentaties zijn te vinden in het mapje [Presentation](https://github.com/Eyegi/14102307/tree/master/Presentation)


## Online Cursussen 2.0

### 2.1 DataCamp
VoorData camp heb ik alle opdrachten af tot en met Week 6 afgemaakt. De Screenshots hiervan zijn te vinden in het mapje [DataCamp](https://github.com/Eyegi/14102307/tree/master/DataCamp).

### 2.2Coursera
Voor Coursera heb ik nu alle opdrachten af en heb ik screenshots gemaakt. Ik vond dit een intressante gedeelte van de minor maar het heeft wel veel tijd gekost.

### 2.3 Notebooks

Een van de online courses die we moesten maken was de note books. Het eerste gedeelte was [ExploratoryDataAnalysis](). 
Toen dat klaar was gingen we over naar [tutorial_spark]() de Notebook files van deze opdrachten zijn te vinden in de [notebooks]().

De resultaten van [Week1](https://github.com/Eyegi/14102307/blob/master/Coursera/CourseraWeek1.PNG).
De resultaten van week 2 zijn te zien in dit [screenshot](https://github.com/Eyegi/14102307/blob/master/Coursera/Coursera%20Week2.PNG), en week 3 kan [hier](https://github.com/Eyegi/14102307/blob/master/Coursera/CourseraWeek3.PNG) gevonden worden. Week 6 is ook compleet en kan in dit [screenshot](https://github.com/Eyegi/14102307/blob/master/Coursera/Coursera%20Week%206.PNG) gevonden worden.

## *3.0 Calling bullshit

*Als onderdeel van de minor moesten wij een course Calling bullshit in the age of datascience doen. Als eind product voor de course moesten wij een paar opdrachten maken en als [verslag]() inleveren.
## 4.0 Issues

###  [Issue 52](https://github.com/urbinn/urbinn/issues/52) Kijken hoe evaluatie TUM is gedaan:
Hierbij moest ik Onderzoek doen Samen met Bob om te kijken howe de evaluatie van de TUM database gedaan was en hierbij een document van maken. 
Dit was nodig omdat wij opzoek waren naar mogelijke evaluatie mogelijkheden voor onze eigen dataset, hieruit is een samenvatting gekomen als [resultaat](https://github.com/Eyegi/14102307/blob/master/Documents/Evaluatie%20TUM%20%26%20ORB%20SLAM2.pdf). 


### [Issue 55](https://github.com/urbinn/urbinn/issues/55) Object detection papers lezen
Hierbij moesten wij de papers van [YOLO](https://github.com/Eyegi/14102307/blob/master/Documents/You%20Only%20Look%20Once%20Unified%2C%20Real-Time%20Object%20Detection%20(1).pdf) en [Mustafa](https://github.com/Eyegi/14102307/blob/master/Documents/mustafah%202012%20Stereo%20vision%20images%20processing%20for%20real-time%20object%20distance%20and%20size%20measurements%20(1).pdf) lezen om te kijken of het toepasbaar zou zijn voor ons project. 
En later werd deze ook de papers die wij moesten lezen voor het tweede sessie van close reading.

### [Issue 57](https://github.com/urbinn/urbinn/issues/57) Beschrijven data structuur KeyFrame in ORB:
Deze ticket heeft wat tijd gekost. 
De bedoeling was om in het code vann ORB SLAM2 Comentaar te schrijven met doxygen die de uitlegd wat elke gedeelte van de code deed. 
Dit heeft tijd genomen omdat je eerst tijd in moet stoppen om de code te begrijpen en uitesten voordat je kanzeggen wat er gebeurt. 
Deze issue heb ik samen met Kevin gedaan. Resultaat is te vinden in [KeyFrame.cc](https://github.com/Eyegi/14102307/blob/master/Code/KeyFrame.cc).

### [Issue 70](https://github.com/urbinn/urbinn/issues/70) KITTI point cloud resultaten:
Bij Deze issue moest de kitty data set door orb slam 2 gehaald worden om csv bestand te krijgen met alle punten voor de point cloud. Orb slam moest op de server van datasience gedraait worden maa er waren isnatlatie problemen in het begin die later zijn opgelost waardoor de KITTI dataset door orb gehaald on worden en de csv bestand te krijgen was. 
Dit is gelukt en hebben we de [csv](https://github.com/Eyegi/14102307/blob/master/Code/map.csv) bestand uitgekregen.

### [Issue 30](https://github.com/urbinn/urbinn/issues/30) SVO uitproberen op test case: 
Hierbij moest ik SVO instaleren en uitproberen op mijn pc het is gelukt om het te installeren en runnen maar halverwegen de images crashed het soms omdat mijn pc niet genoeg rekenkracht voor had. Er is Besloten om verder te gaan met ORB 2 omdat beter leek te passen bij ons en is csv dus ook niet meer uitgebprobeert of gebruikt.
 

### [Issue 37](https://github.com/urbinn/urbinn/issues/37) REMODE onderzoek:
Voor deze issue moest ik onderzoeken of [REMODE-methode](https://github.com/Eyegi/14102307/blob/master/Documents/ICRA14_Pizzoli.pdf) goed was om te gebruiken om afstand te meten uit beelden.
Dit bleek niet bij ons te passen omdat het voor MONO-camera’s waren en wij willen gebruik maken van stereo.

### [Issue 21](https://github.com/urbinn/urbinn/issues/21) Zoeken naar tutorial/video’s voor LSD SLAM:
In het begin van het project moest ik Video’s en of tutorial zoeken die LSD SLAM kon uitleggen zodat het beter te begrijpen werd door de rest van het groepje. Er waren geen duidelijke videos die de werking LSD slam uitlegde.
Meeste videos waren voorbeelden waar met lsd slam gewerkt was.


### *[Issue 46](https://github.com/urbinn/urbinn/issues/46) Visualisatie point/frame:
Voor deze issue heb ik samen met Daniello gekeken hoe wij de orbs van elke afbeelding kon tonen op de afbeelding.
Dit zodat wij een idee konden krijgen waar hij orbs zette en ook ter evaluatie van onze eigen dataset voor de toekomst. 
Het is ons gelukt om de//////////////////////////////////////////////////// [X en Y-coördinatenNOTDONE](/) aan te tonen op de afbeelding maar de berekening van de diepte hebben wij nog niet goedkunnen doen.

### [Issue 91](/https://github.com/urbinn/urbinn/issues/91) ORB2 pointcloud maken slinger:
Voor deze issue moest er een pointcloud gemaakt worden van de slinger om dit te doen moest er eerst een [calibratie bestand](https://github.com/Eyegi/14102307/blob/master/Code/slinger.txt) van de ZED camera geschreven worden met de correcte waardes die orb kan geruiken.
Daara moest de KITTI.cc bestand aangepast worden zodat het gebruikt kon worden voor onze bestanden deze is [slinger.cc](https://github.com/Eyegi/14102307/blob/master/Code/slinger.cc) gewroden. Hierbij moest een paar kleine aanpassingen gedaan worden in de kitti.cc. 
``` cpp
string strPrefixLeft = strPathToSequence + "/left";
string strPrefixRight = strPathToSequence + "/right";
```
om de juiste images te pakken gebruiken wij left en right terwijl kitti 0 en 1 genruikt.
Als laatste moest er ook een [timestamp](https://github.com/Eyegi/14102307/blob/master/Code/timestamps.txt) bestand gemaakt worden 
Bij eerste run hebben wij een coredumb gekregen. wij hebben hierdoor besloten om de code die wij hebben gemaakt om XML bestand te maken even weg te laten en opniew runnen toen ging het goed en hebben wij de [csv](https://github.com/Eyegi/14102307/blob/master/Code/map2.csv) bestand gekregen.

###  [Issue 87](https://github.com/urbinn/urbinn/issues/91) Paper zoeken voor close reading sessie
Hierbij moest ik papers zoeken voor de derde sessie van close reading sessie. De eerste was [Interactive Semantic Mapping: Experimental Evaluation](https://github.com/Eyegi/14102307/blob/master/Documents/14-iser.pdf) en de tweede was [A Proposal for Semantic Map Representation and Evaluation](https://github.com/Eyegi/14102307/blob/master/Documents/1606.03719.pdf).

### *[Issue 81](https://github.com/urbinn/urbinn/issues/81) Literatuur scan: filteren slam met object detectie 
De bedoeling hierbij was om te kijken of er eerder werk is gedaan om objecten die gedetecteerd zjn met bijvoorbeeld YOLO uit slam te filteren zodat je een symantic map kan maken zonder bv autos er in te hebben. Hierbij is er geen eerderwerk gevonden het dichts bijzijnde was objecten duidelijker maken met object detection. Voor deze ticket hebben wij wel twee papers kunnen vinden
die een beetje helpen met onze vragen naamelijk [Object detection ad tracking]() en [Monocular SLAM supported Object Recognition]().

###  [Issue 64](https://github.com/urbinn/urbinn/issues/64) Evaluatie implementatie: pointcloud vs pointcloud
Hierij moest er een manier gevonden worden om de pointcloud te evalueren. Hierbij hebben wij eerst gekeken of het op basis van LiDAR kan gebeuren maar dit was niet mogelijk. Daarna hebben wij gekeken of het kon met de mesh 
die door de ZED camera gemaakt werd maar dit was niet mogelijk omdat de mesh geen loop closure had. Er is ook geprobeert met diepte beelden maar de diepte is relatief en niet "fixed". Wij hebben als tool "Cloud Compare" gruikt maar wij hebben toch geen goeie evaluatie kunnen doen.

### [Issue 79](https://github.com/urbinn/urbinn/issues/79) ORB coordinaten converteren 
Bij deze issue was het de bedoeling om de coordinaten die door orb gegeven waren te vertalen naar meters. Wij waren bezig om dit werkend te krijgen maar wij hebben geen formule gevonden om het goed te kunnen doen, maar zijn ook gestopt hiermee omdat het niet meer nodig was voor ons project.

### [Issue 80](https://github.com/urbinn/urbinn/issues/80)ORB output uitbreiden met keyframe coordinaten

### *[Issue 126](https://github.com/urbinn/urbinn/issues/126)ORB Local Bundle Adjustment
Bij deze punt ben ik overgestapt van ORB naar URB ik moest de [Local Bundle Adjustment](https://github.com/Eyegi/14102307/blob/master/Code/URB/local_ba.cpp) code maken. En later kwam daniello mij hierbij helpen. 

``` cpp
int localBundleAdjustment(Eigen::Ref<Eigen::MatrixXd> keyframes, Eigen::Ref<Eigen::MatrixXd> fixedKeyframes, Eigen::Ref<Eigen::MatrixXd> worldMapPoints, Eigen::Ref<Eigen::MatrixXd> pointsRelation )  {
    //primary keyframe
    KeyFrame primaryKeyframe;
    int primaryKeyframeId = keyframes.row(0)(0) ;
    int secondKeyframeId = keyframes.row(1)(0) ;
    Eigen::MatrixXd primKeyFrame(4, 4);
    //cout << keyframes.row(0) << endl;
    primKeyFrame << keyFrameRowToMatrix(keyframes.row(0) );
    //cout << primKeyFrame << std::endl;
    primaryKeyframe = std::make_pair(std::make_pair(0,keyframes.row(0)(0)) , primKeyFrame);
    
    
    //Prep Data
    //frames with same mappoints as the keyframe
    std::vector<KeyFrame> lLocalKeyFrames;
    
    //add keyframe akka 0
    lLocalKeyFrames.push_back(primaryKeyframe);
    
    for(int n = 1; n < keyframes.rows(); n++) {
        Eigen::MatrixXd currentFrame(4, 4);
        currentFrame << keyFrameRowToMatrix(keyframes.row(n));
        //cout << currentFrame << std::endl;
        //cout << keyframes.row(n)(0) << endl;
        KeyFrame frame = std::make_pair( std::make_pair(n,keyframes.row(n)(0)) , currentFrame);
        lLocalKeyFrames.push_back(frame);
    }
```
### [Issue 113](https://github.com/urbinn/urbinn/issues/113)ORB ORB2: Camera poses uit frames exporteren 

### [Issue 107](https://github.com/urbinn/urbinn/issues/107)ORB Orb2 stability fix 
Bij het maken van grotere pointclouds en incrementeel leren zijn wij er achter gekomen dat de memory leaks te groot werden en dat het programma dan crashed. Dus moesten wij de memory leaks proberen te fixen dit heeft heel veel tijd genomen.

### [Issue 137](https://github.com/urbinn/urbinn/issues/137)ORB Handmatig bepalen welke frame overlappen op Sequence 07 KITTI 
Hierbij ben ik begonnen met het zoeken door de trajectory te plotten van sequence 7. Eerst in kleine stappen todat ze elkaar "berijken" dan deze frame gekozen als de frames voor loopclosure.
Daarna heb ik de photos getekens met behulp van python scripts in notebooks om de plaatjes te kijken en vergelijken.
![Matching position for loop closure](https://github.com/Eyegi/14102307/blob/master/Images/MatchingForBASeq7.PNG "Image 1 and 1060")

### *[Issue 136](https://github.com/urbinn/urbinn/issues/136)ORB Full BA code schrijven 
Voor deze issue moest de code voor [full Bundle adjustment](https://github.com/Eyegi/14102307/blob/master/Code/URB/full_ba.cpp) gemaakt worden en getest hiervoor is issue 137 nodig.

### [Issue 132](https://github.com/urbinn/urbinn/issues/132)ORB Efficient depth estimation 
De bedoeling van deze issue was om te kijken of depth estimation sneller gemaakt kon worden maar dit was even op hold gezet om Full bundle adjustment te maken.





